<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Memory Performance ELI5 &#8212; BEAM VM Wisdoms</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="BEAM Definitions" href="definitions.html" />
    <link rel="prev" title="Efficiency ELI5" href="eli5-efficiency.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
<section id="memory-performance-eli5">
<h1>Memory Performance ELI5<a class="headerlink" href="#memory-performance-eli5" title="Permalink to this heading">¶</a></h1>
<section id="data-locality">
<h2>Data Locality<a class="headerlink" href="#data-locality" title="Permalink to this heading">¶</a></h2>
<p>In recent decades performance of computer memory did not grow as fast as
performance of CPUs has improved.
To offset impact of memory low performance several levels of CPU caches
are used which store recently accessed data closer to the CPU.
When you access any byte in memory, larger blocks of data are loaded to
cache or flushed at once (these are called cache rows).</p>
<p>The general rule of gaining best performance is to store relevant data close
together. From Erlang point of view it means also creating all
relevant data together which will place them together in process heap.</p>
<p>If the data is large, it should be grouped to allow sequential
processing. And the cost of memory access can be so high that some values
are cheaper to calculate instead of loading them from some cold
(uncached and rarely read) memory location.</p>
<p>Hot (often accessed) memory is a welcome place to store
your variables and working data, for C and C++ programs this is program stack
and for C++ this would be fields of your current class object, because it
always was accessed recently. It is harder to say which memory is hot for
Erlang, as we don’t control much of its behaviour, but there are some tricks
that affect data placement on heap and how it will perform after.</p>
</section>
<section id="cache-miss">
<h2>Cache Miss<a class="headerlink" href="#cache-miss" title="Permalink to this heading">¶</a></h2>
<p>A “cache miss” is a special situation which occurs when CPU accesses some data
and the data wasn’t in cache. A cache row (64 bytes) of data are requested
from main RAM. CPU is forced to wait for the data. If possible the CPU
will try and do some other work by reordering machine instructions, but
this does not always happen and just assume that it is waiting for the data.</p>
<p>Typical cost of a cache miss is ~100 CPU cycles. This is a lot of time,
many simpler values can be calculated without accessing memory and save
significant time with not reading the main RAM.</p>
<p>Even worse if your program runs on a large production server with hundreds
GB of memory, then most likely it uses non-uniform memory architecture (NUMA)
and the memory is divided between CPU cores. The cost of a cache miss on
such machines is even higher, especially if accessing part of RAM “owned”
by another CPU core. Erlang and BEAM VM is aware about this and does its
best to preserve the core locality of used memory.</p>
<p>So when you are optimizing your awesome algorithm which now is perfect and
doesn’t run any better no matter the effort, have a look at how it works with
memory. The reward for using memory efficiently is your code running
much faster!</p>
</section>
<section id="data-types">
<h2>Data Types<a class="headerlink" href="#data-types" title="Permalink to this heading">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Major garbage collection of a process will order its data in
memory by placing all list cells together, and tuple values will follow the
tuple in memory. This is very good for memory locality although moving all
this data might be super expensive.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>For memory-heavy operations</strong>
consider owning the data in the process which does the work instead of
requesting it from ETS or database while doing the work.
Keeping at most one memory-intensive process per available CPU core is
welcome, let the BEAM VM do the rest for you.
Also consider doing a major GC on your worker process before running a
big calculation (see <code class="docutils literal notranslate"><span class="pre">erlang:garbage_collect</span></code>).</p>
</div>
<section id="immediate-values">
<h3>Immediate Values<a class="headerlink" href="#immediate-values" title="Permalink to this heading">¶</a></h3>
<p>These values are smallest, they always fit into a CPU register and there is
not much you can do to make them work any faster. They are atoms,
small integers, local pids etc.</p>
</section>
<section id="lists">
<h3>Lists<a class="headerlink" href="#lists" title="Permalink to this heading">¶</a></h3>
<p>Lists in BEAM are represented as single-linked lists of value pairs (cells).
If a list is created in a complex algorithm slowly, its cells might be sparsely
distributed in memory interleaved with other data created at the same time.
This may lead to inefficient CPU cache usage. A way to offset this
is to create your large working lists in tight loops while not creating other
unnecessary data. This will place list cells tightly together with their values.
When it is not possible, you can always invoke a major garbage collection and
have everything sorted for you (at a cost).</p>
</section>
<section id="tuples">
<h3>Tuples<a class="headerlink" href="#tuples" title="Permalink to this heading">¶</a></h3>
<p>As tuples are stored as arrays, they are cache friendly. If a tuple contains
other data structures such as lists or tuples, the data will be stored somewhere
else on heap and the tuple will only contain pointers to it.
Even better if a major garbage collection was performed recently which sorts
your data in memory and groups it together.</p>
</section>
<section id="floats">
<h3>Floats<a class="headerlink" href="#floats" title="Permalink to this heading">¶</a></h3>
<p>Even if a floating point value fits into a CPU register and has same size as
an immediate value (small integer or atom etc), actually they are
stored on-heap with a header word marking their presence. This makes floats
consume double the memory and each access to them will dereference a pointer
to a possibly cold memory location where no other floats are stored.</p>
<p>Best you can do here is to create your arrays or lists of floating point values
in tight loop together, which will maximize how many floats are cached when
a single cache row of 64 bytes is loaded.
Or run a major GC to group them automatically.</p>
</section>
<section id="ets-tables">
<h3>ETS Tables<a class="headerlink" href="#ets-tables" title="Permalink to this heading">¶</a></h3>
<p>There is not much you can do to affect ETS table memory behaviour, so here
you are at the mercy of BEAM VM developers.</p>
</section>
</section>
</section>


<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-84125230-1', 'auto');
ga('send', 'pageview');
</script>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div style="margin-bottom:16px;">
    <a href="http://beam-wisdoms.clau.se/" alt="Wisdoms Home Page"
    title="Return to the Home Page"><img src="_static/img/bw_logo.png" width="200"></a>
</div>


<h1 class="logo"><a href="index.html">BEAM VM Wisdoms</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="eli5-vm.html">BEAM VM ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-atoms.html">Atoms ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-processes.html">Processes ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-process-heap.html">Process Heaps ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-io.html">Input/Output and Ports ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-tracing.html">Tracing ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-bif-nif.html">BIF and NIF functions ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-types.html">Types ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-etf.html">External Term Format ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-property-based.html">Property Based Testing ELI5</a></li>
<li class="toctree-l1"><a class="reference internal" href="eli5-efficiency.html">Efficiency ELI5</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Memory Performance ELI5</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="definitions.html">BEAM Definitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="indepth-memory-layout.html">Data Types Memory Layout</a></li>
<li class="toctree-l1"><a class="reference internal" href="indepth-data-sizes.html">BEAM Internal data sizes</a></li>
<li class="toctree-l1"><a class="reference internal" href="indepth-heap-layout.html">Process Heap Layout</a></li>
<li class="toctree-l1"><a class="reference internal" href="interfacing.html">Interfacing Erlang with the Outer World</a></li>
<li class="toctree-l1"><a class="reference internal" href="indepth-beam-file.html">BEAM File Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="indepth-beam-instructions.html">BEAM Instruction Codes</a></li>
<li class="toctree-l1"><a class="reference internal" href="indepth-io.html">IO in Erlang</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="eli5-efficiency.html" title="previous chapter">Efficiency ELI5</a></li>
      <li>Next: <a href="definitions.html" title="next chapter">BEAM Definitions</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016-2017, Dmytro "kvakvs" Lytovchenko.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/eli5-efficiency-memory-perf.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>